{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxkEfZ474LIWx1J3YHauKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devsjee/devsjee/blob/main/Text_summarization_using_LangChain_and_Gemini_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi there!\n",
        "\n",
        "Text summarization is a beautiful cognitive task in which humans go through a piece of context and somehow magically come up with a gist of it such as in the example below:\n",
        "\n",
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "It is evident that different people will come up with different summaries according to their own perspectives. I have always wondered about how to automatically construct a summary of a given text. There were some very good logical attempts of extractive and absractive summarizations such as using frequency counts, lex rank, text rank, LSA, ESA, Lexical Chains, etc. However, in the current LLM era, deep learning models are achieving close to impeccable results in the text summarization task!"
      ],
      "metadata": {
        "id": "YtWTQ_t7LPeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why not create a text summarization module using LLMs and experience its summarization skills? I am going to closely follow the below tutorial to build my summarization model.\n",
        "\n",
        "\n",
        "Reference: https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb"
      ],
      "metadata": {
        "id": "oZabFu9gR4ty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfwfCETSqU3A",
        "outputId": "c65920a7-713f-42fc-989b-8ca069c3418d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.3-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.15-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.14 (from langchain)\n",
            "  Downloading langchain_core-0.1.16-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m610.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.3 langchain-community-0.0.15 langchain-core-0.1.16 langsmith-0.0.83 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ht8Vlu2r2l7",
        "outputId": "35054144-9182-4da4-d3d0-77e200001602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.6-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.16)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.5.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.0.83)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2023.11.17)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.5.1)\n",
            "Installing collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = getpass.getpass(\"Enter the GOOGLE API KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAE_Lf1UsE_N",
        "outputId": "94a2f331-3c96-4149-ef6d-2133c520b921"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the GOOGLE API KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.document_loaders import WebBaseLoader\n"
      ],
      "metadata": {
        "id": "-BnOjqW1xafG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\n",
        "docs = loader.load()\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6qYVrv0HZ2",
        "outputId": "f1f334da-d276-4e5d-d220-89821c08e71a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"\\n\\n\\n\\n\\n\\nIntroducing Gemini: Google’s most capable AI model yet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n        The Keyword\\n      \\n\\n\\n\\n\\n    Introducing Gemini: our largest and most capable AI model\\n  \\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nMail\\n\\n\\n\\n\\n\\n\\nCopy link\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n               Latest stories\\n            \\n\\n\\n\\n              Product updates\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Product updates\\n  \\n\\n\\n\\n            Android, Chrome & Play\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Android\\n                  \\n                \\n\\n\\n\\n                  Chrome\\n                  \\n                \\n\\n\\n\\n                  Chromebooks\\n                  \\n                \\n\\n\\n\\n                  Google Play\\n                  \\n                \\n\\n\\n\\n                  Wear OS by Google\\n                  \\n                \\n\\n\\n\\n\\n\\n            Devices & Services\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Chromecast\\n                  \\n                \\n\\n\\n\\n                  Fitbit\\n                  \\n                \\n\\n\\n\\n                  Google Nest\\n                  \\n                \\n\\n\\n\\n                  Pixel\\n                  \\n                \\n\\n\\n\\n\\n\\n            Explore & Get Answers\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Bard\\n                  \\n                \\n\\n\\n\\n                  Google Assistant\\n                  \\n                \\n\\n\\n\\n                  Maps\\n                  \\n                \\n\\n\\n\\n                  News\\n                  \\n                \\n\\n\\n\\n                  Search\\n                  \\n                \\n\\n\\n\\n                  Shopping\\n                  \\n                \\n\\n\\n\\n\\n\\n            Connect & Communicate\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Photos\\n                  \\n                \\n\\n\\n\\n                  Translate\\n                  \\n                \\n\\n\\n\\n                  Registry\\n                  \\n                \\n\\n\\n\\n\\n\\n            In The Cloud\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Docs, Sheets and Slides\\n                  \\n                \\n\\n\\n\\n                  Gmail\\n                  \\n                \\n\\n\\n\\n                  Google Cloud\\n                  \\n                \\n\\n\\n\\n                  Meet\\n                  \\n                \\n\\n\\n\\n                  More on the Cloud Blog\\n                  \\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n      See all product updates\\n    \\n\\n\\n\\n\\n\\n            Android, Chrome & Play\\n          \\n\\n\\n\\n                    Android\\n\\n                    \\n                  \\n\\n\\n\\n                    Chrome\\n\\n                    \\n                  \\n\\n\\n\\n                    Chromebooks\\n\\n                    \\n                  \\n\\n\\n\\n                    Google Play\\n\\n                    \\n                  \\n\\n\\n\\n                    Wear OS by Google\\n\\n                    \\n                  \\n\\n\\n\\n\\n\\n            Devices & Services\\n          \\n\\n\\n\\n                    Chromecast\\n\\n                    \\n                  \\n\\n\\n\\n                    Fitbit\\n\\n                    \\n                  \\n\\n\\n\\n                    Google Nest\\n\\n                    \\n                  \\n\\n\\n\\n                    Pixel\\n\\n                    \\n                  \\n\\n\\n\\n\\n\\n            Explore & Get Answers\\n          \\n\\n\\n\\n                    Bard\\n\\n                    \\n                  \\n\\n\\n\\n                    Google Assistant\\n\\n                    \\n                  \\n\\n\\n\\n                    Maps\\n\\n                    \\n                  \\n\\n\\n\\n                    News\\n\\n                    \\n                  \\n\\n\\n\\n                    Search\\n\\n                    \\n                  \\n\\n\\n\\n                    Shopping\\n\\n                    \\n                  \\n\\n\\n\\n\\n\\n            Connect & Communicate\\n          \\n\\n\\n\\n                    Photos\\n\\n                    \\n                  \\n\\n\\n\\n                    Translate\\n\\n                    \\n                  \\n\\n\\n\\n                    Registry\\n\\n                    \\n                  \\n\\n\\n\\n\\n\\n            In The Cloud\\n          \\n\\n\\n\\n                    Docs, Sheets and Slides\\n\\n                    \\n                  \\n\\n\\n\\n                    Gmail\\n\\n                    \\n                  \\n\\n\\n\\n                    Google Cloud\\n\\n                    \\n                  \\n\\n\\n\\n                    Meet\\n\\n                    \\n                  \\n\\n\\n\\n                    More on the Cloud Blog\\n\\n                    \\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        See all product updates\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Company news\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Company news\\n  \\n\\n\\n\\n            Outreach & initiatives\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Diversity and inclusion\\n                  \\n                \\n\\n\\n\\n                  Education\\n                  \\n                \\n\\n\\n\\n                  Google.org\\n                  \\n                \\n\\n\\n\\n                  Grow with Google\\n                  \\n                \\n\\n\\n\\n                  Sustainability\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Technology\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  AI\\n                  \\n                \\n\\n\\n\\n                  Developers\\n                  \\n                \\n\\n\\n\\n                  Families\\n                  \\n                \\n\\n\\n\\n                  Next billion users\\n                  \\n                \\n\\n\\n\\n                  Safety and security\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Inside Google\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Data centers and infrastructure\\n                  \\n                \\n\\n\\n\\n                  Doodles\\n                  \\n                \\n\\n\\n\\n                  Googlers\\n                  \\n                \\n\\n\\n\\n                  Life at Google\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Around the globe\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Google in Asia\\n                  \\n                \\n\\n\\n\\n                  Google in Europe\\n                  \\n                \\n\\n\\n\\n                  Google in Latin America\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Authors\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Sundar Pichai, CEO\\n                  \\n                \\n\\n\\n\\n                  Ruth Porat, SVP and CFO\\n                  \\n                \\n\\n\\n\\n                  Kent Walker, SVP\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Outreach & initiatives\\n          \\n\\n\\n\\n                    Diversity and inclusion\\n\\n                    \\n                  \\n\\n\\n\\n                    Education\\n\\n                    \\n                  \\n\\n\\n\\n                    Google.org\\n\\n                    \\n                  \\n\\n\\n\\n                    Grow with Google\\n\\n                    \\n                  \\n\\n\\n\\n                    Sustainability\\n\\n                    \\n                  \\n\\n\\n\\n            See all\\n            \\n\\n\\n\\n\\n\\n\\n            Technology\\n          \\n\\n\\n\\n                    AI\\n\\n                    \\n                  \\n\\n\\n\\n                    Developers\\n\\n                    \\n                  \\n\\n\\n\\n                    Families\\n\\n                    \\n                  \\n\\n\\n\\n                    Next billion users\\n\\n                    \\n                  \\n\\n\\n\\n                    Safety and security\\n\\n                    \\n                  \\n\\n\\n\\n            See all\\n            \\n\\n\\n\\n\\n\\n\\n            Inside Google\\n          \\n\\n\\n\\n                    Data centers and infrastructure\\n\\n                    \\n                  \\n\\n\\n\\n                    Doodles\\n\\n                    \\n                  \\n\\n\\n\\n                    Googlers\\n\\n                    \\n                  \\n\\n\\n\\n                    Life at Google\\n\\n                    \\n                  \\n\\n\\n\\n            See all\\n            \\n\\n\\n\\n\\n\\n\\n            Around the globe\\n          \\n\\n\\n\\n                    Google in Asia\\n\\n                    \\n                  \\n\\n\\n\\n                    Google in Europe\\n\\n                    \\n                  \\n\\n\\n\\n                    Google in Latin America\\n\\n                    \\n                  \\n\\n\\n\\n            See all\\n            \\n\\n\\n\\n\\n\\n\\n            Authors\\n          \\n\\n\\n\\n                    Sundar Pichai, CEO\\n\\n                    \\n                  \\n\\n\\n\\n                    Ruth Porat, SVP and CFO\\n\\n                    \\n                  \\n\\n\\n\\n                    Kent Walker, SVP\\n\\n                    \\n                  \\n\\n\\n\\n            See all\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Subscribe\\n\\n\\n\\n\\n\\n\\n\\n    Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            The Keyword\\n          \\n\\n\\n\\n\\n\\n\\n\\n               Latest stories\\n            \\n\\n\\n\\n              Product updates\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Product updates\\n  \\n\\n\\n\\n            Android, Chrome & Play\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Android\\n                  \\n                \\n\\n\\n\\n                  Chrome\\n                  \\n                \\n\\n\\n\\n                  Chromebooks\\n                  \\n                \\n\\n\\n\\n                  Google Play\\n                  \\n                \\n\\n\\n\\n                  Wear OS by Google\\n                  \\n                \\n\\n\\n\\n\\n\\n            Devices & Services\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Chromecast\\n                  \\n                \\n\\n\\n\\n                  Fitbit\\n                  \\n                \\n\\n\\n\\n                  Google Nest\\n                  \\n                \\n\\n\\n\\n                  Pixel\\n                  \\n                \\n\\n\\n\\n\\n\\n            Explore & Get Answers\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Bard\\n                  \\n                \\n\\n\\n\\n                  Google Assistant\\n                  \\n                \\n\\n\\n\\n                  Maps\\n                  \\n                \\n\\n\\n\\n                  News\\n                  \\n                \\n\\n\\n\\n                  Search\\n                  \\n                \\n\\n\\n\\n                  Shopping\\n                  \\n                \\n\\n\\n\\n\\n\\n            Connect & Communicate\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Photos\\n                  \\n                \\n\\n\\n\\n                  Translate\\n                  \\n                \\n\\n\\n\\n                  Registry\\n                  \\n                \\n\\n\\n\\n\\n\\n            In The Cloud\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Docs, Sheets and Slides\\n                  \\n                \\n\\n\\n\\n                  Gmail\\n                  \\n                \\n\\n\\n\\n                  Google Cloud\\n                  \\n                \\n\\n\\n\\n                  Meet\\n                  \\n                \\n\\n\\n\\n                  More on the Cloud Blog\\n                  \\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n      See all product updates\\n    \\n\\n\\n\\n\\n              Company news\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Company news\\n  \\n\\n\\n\\n            Outreach & initiatives\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Diversity and inclusion\\n                  \\n                \\n\\n\\n\\n                  Education\\n                  \\n                \\n\\n\\n\\n                  Google.org\\n                  \\n                \\n\\n\\n\\n                  Grow with Google\\n                  \\n                \\n\\n\\n\\n                  Sustainability\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Technology\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  AI\\n                  \\n                \\n\\n\\n\\n                  Developers\\n                  \\n                \\n\\n\\n\\n                  Families\\n                  \\n                \\n\\n\\n\\n                  Next billion users\\n                  \\n                \\n\\n\\n\\n                  Safety and security\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Inside Google\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Data centers and infrastructure\\n                  \\n                \\n\\n\\n\\n                  Doodles\\n                  \\n                \\n\\n\\n\\n                  Googlers\\n                  \\n                \\n\\n\\n\\n                  Life at Google\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Around the globe\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Google in Asia\\n                  \\n                \\n\\n\\n\\n                  Google in Europe\\n                  \\n                \\n\\n\\n\\n                  Google in Latin America\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n            Authors\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n                  Sundar Pichai, CEO\\n                  \\n                \\n\\n\\n\\n                  Ruth Porat, SVP and CFO\\n                  \\n                \\n\\n\\n\\n                  Kent Walker, SVP\\n                  \\n                \\n\\n\\n\\n                   See all\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Press corner\\n          \\n\\n\\n\\n            RSS feed\\n          \\n\\n\\n\\n\\n\\n    Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI\\n\\n\\nIntroducing Gemini: our largest and most capable AI model\\n\\n\\n\\n\\n\\n\\n\\nDec 06, 2023\\nmin read\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nMail\\n\\n\\n\\n\\n\\n\\nCopy link\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Making AI more helpful for everyone\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSundar Pichai\\n\\n      CEO of Google and Alphabet\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDemis Hassabis\\n\\n      CEO and Co-Founder, Google DeepMind\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nMail\\n\\n\\n\\n\\n\\n\\nCopy link\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIn this story\\n\\n\\nIn this story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNote from Sundar\\n\\n\\nIntroducing Gemini\\n\\n\\nState-of-the-art performance\\n\\n\\nNext-generation capabilities\\n\\n\\nScalable and efficient\\n\\n\\nResponsibility and safety\\n\\n\\nAvailability\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA note from Google and Alphabet CEO Sundar Pichai:Every technology shift is an opportunity to advance scientific discovery, accelerate human progress, and improve lives. I believe the transition we are seeing right now with AI will be the most profound in our lifetimes, far bigger than the shift to mobile or to the web before it. AI has the potential to create opportunities — from the everyday to the extraordinary — for people everywhere. It will bring new waves of innovation and economic progress and drive knowledge, learning, creativity and productivity on a scale we haven’t seen before.That’s what excites me: the chance to make AI helpful for everyone, everywhere in the world.Nearly eight years into our journey as an AI-first company, the pace of progress is only accelerating: Millions of people are now using generative AI across our products to do things they couldn’t even a year ago, from finding answers to more complex questions to using new tools to collaborate and create. At the same time, developers are using our models and infrastructure to build new generative AI applications, and startups and enterprises around the world are growing with our AI tools.This is incredible momentum, and yet, we’re only beginning to scratch the surface of what’s possible.We’re approaching this work boldly and responsibly. That means being ambitious in our research and pursuing the capabilities that will bring enormous benefits to people and society, while building in safeguards and working collaboratively with governments and experts to address risks as AI becomes more capable. And we continue to invest in the very best tools, foundation models and infrastructure and bring them to our products and to others, guided by our AI Principles.Now, we’re taking the next step on our journey with Gemini, our most capable and general model yet, with state-of-the-art performance across many leading benchmarks. Our first version, Gemini 1.0, is optimized for different sizes: Ultra, Pro and Nano. These are the first models of the Gemini era and the first realization of the vision we had when we formed Google DeepMind earlier this year. This new era of models represents one of the biggest science and engineering efforts we’ve undertaken as a company. I’m genuinely excited for what’s ahead, and for the opportunities Gemini will unlock for people everywhere.– Sundar\\n\\n\\n\\n\\n\\nIntroducing GeminiBy Demis Hassabis, CEO and Co-Founder of Google DeepMind, on behalf of the Gemini teamAI has been the focus of my life's work, as for many of my research colleagues. Ever since programming AI for computer games as a teenager, and throughout my years as a neuroscience researcher trying to understand the workings of the brain, I’ve always believed that if we could build smarter machines, we could harness them to benefit humanity in incredible ways.This promise of a world responsibly empowered by AI continues to drive our work at Google DeepMind. For a long time, we’ve wanted to build a new generation of AI models, inspired by the way people understand and interact with the world. AI that feels less like a smart piece of software and more like something useful and intuitive — an expert helper or assistant.Today, we’re a step closer to this vision as we introduce Gemini, the most capable and general model we’ve ever built.Gemini is the result of large-scale collaborative efforts by teams across Google, including our colleagues at Google Research. It was built from the ground up to be multimodal, which means it can generalize and seamlessly understand, operate across and combine different types of information including text, code, audio, image and video.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10:25\\n\\n\\n\\n\\nIntroducing Gemini: our largest and most capable AI model\\n\\n\\n\\n\\n\\n\\nGemini is also our most flexible model yet — able to efficiently run on everything from data centers to mobile devices. Its state-of-the-art capabilities will significantly enhance the way developers and enterprise customers build and scale with AI.We’ve optimized Gemini 1.0, our first version, for three different sizes:Gemini Ultra — our largest and most capable model for highly complex tasks.Gemini Pro — our best model for scaling across a wide range of tasks.Gemini Nano — our most efficient model for on-device tasks.\\n\\n\\n\\n\\n\\nState-of-the-art performanceWe've been rigorously testing our Gemini models and evaluating their performance on a wide variety of tasks. From natural image, audio and video understanding to mathematical reasoning, Gemini Ultra’s performance exceeds current state-of-the-art results on 30 of the 32 widely-used academic benchmarks used in large language model (LLM) research and development.With a score of 90.0%, Gemini Ultra is the first model to outperform human experts on MMLU (massive multitask language understanding), which uses a combination of 57 subjects such as math, physics, history, law, medicine and ethics for testing both world knowledge and problem-solving abilities.Our new benchmark approach to MMLU enables Gemini to use its reasoning capabilities to think more carefully before answering difficult questions, leading to significant improvements over just using its first impression.\\n\\n\\n\\n\\n\\n\\nGemini surpasses state-of-the-art performance on a range of benchmarks including text and coding.\\n\\n\\n\\nGemini Ultra also achieves a state-of-the-art score of 59.4% on the new MMMU benchmark, which consists of multimodal tasks spanning different domains requiring deliberate reasoning.With the image benchmarks we tested, Gemini Ultra outperformed previous state-of-the-art models, without assistance from optical character recognition (OCR) systems that extract text from images for further processing. These benchmarks highlight Gemini’s native multimodality and indicate early signs of Gemini's more complex reasoning abilities.See more details in our Gemini technical report.\\n\\n\\n\\n\\n\\n\\nGemini surpasses state-of-the-art performance on a range of multimodal benchmarks.\\n\\n\\n\\n\\nNext-generation capabilitiesUntil now, the standard approach to creating multimodal models involved training separate components for different modalities and then stitching them together to roughly mimic some of this functionality. These models can sometimes be good at performing certain tasks, like describing images, but struggle with more conceptual and complex reasoning.We designed Gemini to be natively multimodal, pre-trained from the start on different modalities. Then we fine-tuned it with additional multimodal data to further refine its effectiveness. This helps Gemini seamlessly understand and reason about all kinds of inputs from the ground up, far better than existing multimodal models — and its capabilities are state of the art in nearly every domain.Learn more about Gemini’s capabilities and see how it works.Sophisticated reasoningGemini 1.0’s sophisticated multimodal reasoning capabilities can help make sense of complex written and visual information. This makes it uniquely skilled at uncovering knowledge that can be difficult to discern amid vast amounts of data.Its remarkable ability to extract insights from hundreds of thousands of documents through reading, filtering and understanding information will help deliver new breakthroughs at digital speeds in many fields from science to finance.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10:25\\n\\n\\n\\n\\nGemini unlocks new scientific insights\\n\\n\\n\\n\\n\\n\\nUnderstanding text, images, audio and moreGemini 1.0 was trained to recognize and understand text, images, audio and more at the same time, so it better understands nuanced information and can answer questions relating to complicated topics. This makes it especially good at explaining reasoning in complex subjects like math and physics.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10:25\\n\\n\\n\\n\\nGemini explains reasoning in math and physics\\n\\n\\n\\n\\n\\n\\nAdvanced codingOur first version of Gemini can understand, explain and generate high-quality code in the world’s most popular programming languages, like Python, Java, C++, and Go. Its ability to work across languages and reason about complex information makes it one of the leading foundation models for coding in the world.Gemini Ultra excels in several coding benchmarks, including HumanEval, an important industry-standard for evaluating performance on coding tasks, and Natural2Code, our internal held-out dataset, which uses author-generated sources instead of web-based information.Gemini can also be used as the engine for more advanced coding systems. Two years ago we presented AlphaCode, the first AI code generation system to reach a competitive level of performance in programming competitions.Using a specialized version of Gemini, we created a more advanced code generation system, AlphaCode 2, which excels at solving competitive programming problems that go beyond coding to involve complex math and theoretical computer science.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10:25\\n\\n\\n\\n\\nGemini excels at coding and competitive programming\\n\\n\\n\\n\\n\\n\\nWhen evaluated on the same platform as the original AlphaCode, AlphaCode 2 shows massive improvements, solving nearly twice as many problems, and we estimate that it performs better than 85% of competition participants — up from nearly 50% for AlphaCode. When programmers collaborate with AlphaCode 2 by defining certain properties for the code samples to follow, it performs even better.We’re excited for programmers to increasingly use highly capable AI models as collaborative tools that can help them reason about the problems, propose code designs and assist with implementation — so they can release apps and design better services, faster.See more details in our AlphaCode 2 technical report.\\n\\n\\n\\n\\n\\nMore reliable, scalable and efficientWe trained Gemini 1.0 at scale on our AI-optimized infrastructure using Google’s in-house designed Tensor Processing Units (TPUs) v4 and v5e. And we designed it to be our most reliable and scalable model to train, and our most efficient to serve.On TPUs, Gemini runs significantly faster than earlier, smaller and less-capable models. These custom-designed AI accelerators have been at the heart of Google's AI-powered products that serve billions of users like Search, YouTube, Gmail, Google Maps, Google Play and Android. They’ve also enabled companies around the world to train large-scale AI models cost-efficiently.Today, we’re announcing the most powerful, efficient and scalable TPU system to date, Cloud TPU v5p, designed for training cutting-edge AI models. This next generation TPU will accelerate Gemini’s development and help developers and enterprise customers train large-scale generative AI models faster, allowing new products and capabilities to reach customers sooner.\\n\\n\\n\\n\\n\\n\\nA row of Cloud TPU v5p AI accelerator supercomputers in a Google data center.\\n\\n\\n\\n\\nBuilt with responsibility and safety at the coreAt Google, we’re committed to advancing bold and responsible AI in everything we do. Building upon Google’s AI Principles and the robust safety policies across our products, we’re adding new protections to account for Gemini’s multimodal capabilities. At each stage of development, we’re considering potential risks and working to test and mitigate them.Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. We’ve conducted novel research into potential risk areas like cyber-offense, persuasion and autonomy, and have applied Google Research’s best-in-class adversarial testing techniques to help identify critical safety issues in advance of Gemini’s deployment.To identify blindspots in our internal evaluation approach, we’re working with a diverse group of external experts and partners to stress-test our models across a range of issues.To diagnose content safety issues during Gemini’s training phases and ensure its output follows our policies, we’re using benchmarks such as Real Toxicity Prompts, a set of 100,000 prompts with varying degrees of toxicity pulled from the web, developed by experts at the Allen Institute for AI. Further details on this work are coming soon.To limit harm, we built dedicated safety classifiers to identify, label and sort out content involving violence or negative stereotypes, for example. Combined with robust filters, this layered approach is designed to make Gemini safer and more inclusive for everyone. Additionally, we’re continuing to address known challenges for models such as factuality, grounding, attribution and corroboration.Responsibility and safety will always be central to the development and deployment of our models. This is a long-term commitment that requires building collaboratively, so we’re partnering with the industry and broader ecosystem on defining best practices and setting safety and security benchmarks through organizations like MLCommons, the Frontier Model Forum and its AI Safety Fund, and our Secure AI Framework (SAIF), which was designed to help mitigate security risks specific to AI systems across the public and private sectors. We’ll continue partnering with researchers, governments and civil society groups around the world as we develop Gemini.\\n\\n\\n\\n\\n\\nMaking Gemini available to the worldGemini 1.0 is now rolling out across a range of products and platforms:Gemini Pro in Google productsWe’re bringing Gemini to billions of people through Google products.Starting today, Bard will use a fine-tuned version of Gemini Pro for more advanced reasoning, planning, understanding and more. This is the biggest upgrade to Bard since it launched. It will be available in English in more than 170 countries and territories, and we plan to expand to different modalities and support new languages and locations in the near future.We’re also bringing Gemini to Pixel. Pixel 8 Pro is the first smartphone engineered to run Gemini Nano, which is powering new features like Summarize in the Recorder app and rolling out in Smart Reply in Gboard, starting with WhatsApp, Line and KakaoTalk1 — with more messaging apps coming next year.In the coming months, Gemini will be available in more of our products and services like Search, Ads, Chrome and Duet AI.We’re already starting to experiment with Gemini in Search, where it's making our Search Generative Experience (SGE) faster for users, with a 40% reduction in latency in English in the U.S., alongside improvements in quality.Building with GeminiStarting on December 13, developers and enterprise customers can access Gemini Pro via the Gemini API in Google AI Studio or Google Cloud Vertex AI.Google AI Studio is a free, web-based developer tool to prototype and launch apps quickly with an API key. When it's time for a fully-managed AI platform, Vertex AI allows customization of Gemini with full data control and benefits from additional Google Cloud features for enterprise security, safety, privacy and data governance and compliance.Android developers will also be able to build with Gemini Nano, our most efficient model for on-device tasks, via AICore, a new system capability available in Android 14, starting on Pixel 8 Pro devices. Sign up for an early preview of AICore.Gemini Ultra coming soonFor Gemini Ultra, we’re currently completing extensive trust and safety checks, including red-teaming by trusted external parties, and further refining the model using fine-tuning and reinforcement learning from human feedback (RLHF) before making it broadly available.As part of this process, we’ll make Gemini Ultra available to select customers, developers, partners and safety and responsibility experts for early experimentation and feedback before rolling it out to developers and enterprise customers early next year.Early next year, we’ll also launch Bard Advanced, a new, cutting-edge AI experience that gives you access to our best models and capabilities, starting with Gemini Ultra.\\n\\n\\n\\n\\nThe Gemini era: enabling a future of innovationThis is a significant milestone in the development of AI, and the start of a new era for us at Google as we continue to rapidly innovate and responsibly advance the capabilities of our models.We’ve made great progress on Gemini so far and we’re working hard to further extend its capabilities for future versions, including advances in planning and memory, and increasing the context window for processing even more information to give better responses.We’re excited by the amazing possibilities of a world responsibly empowered by AI — a future of innovation that will enhance creativity, extend knowledge, advance science and transform the way billions of people live and work around the world.\\n\\n\\n\\n\\n\\n\\n\\n\\nCollection\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCollection\\n\\nMore about Gemini\\nExplore our collection to find out more about Gemini, the most capable and general model we’ve ever built.\\n\\nSee more\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Get more stories from Google in your inbox.\\n        \\n\\n\\n\\n\\n\\n    Email address\\n  \\n\\n\\n\\n\\n\\n              Your information will be used in accordance with\\n            \\nGoogle's privacy policy.\\n\\n\\n            Subscribe\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDone. Just one step more.\\n\\nCheck your inbox to confirm your subscription.\\n\\nYou are already subscribed to our newsletter.\\n\\n\\n\\n          You can also subscribe with a\\n        \\ndifferent email address\\n\\n        .\\n        \\n\\n\\n\\n\\n\\n\\nPOSTED IN:\\n\\n\\n\\n\\n\\n\\nAI\\n\\n\\n  \\n\\n\\n\\n\\n\\nBard\\n\\n\\n  \\n\\n\\n\\n\\n\\nDevelopers\\n\\n\\n  \\n\\n\\n\\n\\n\\nGoogle Cloud\\n\\n\\n  \\n\\n\\n\\n\\n\\nResearch\\n\\n\\n  \\n\\n\\n\\n\\n\\nGoogle DeepMind\\n\\n\\n  \\n\\n\\n\\n\\n\\nPixel\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRead Article\\n\\n\\n\\n\\n\\n\\n\\nMore Information\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n1\\n\\nUpdated on Dec 13 to include additional messaging apps\\n\\n\\n\\nCollapse\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Related stories\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPixel\\nHow we built and tested body temperature on Pixel 8 Pro\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Molly McHugh-Johnson\\n                    \\n\\n Jan 25, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPixel\\nNew Pixel features for a minty fresh start to the year\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Stephanie Scott\\n                    \\n\\n Jan 25, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nChrome\\nChrome is getting 3 new generative AI features\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Parisa Tabriz\\n                    \\n\\n Jan 23, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPixel\\nHow to use Battery Saver on your Pixel devices\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Michael Krumboltz\\n                    \\n\\n Jan 22, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPixel\\nHow Pixel is helping pups find their fur-ever homes\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Chaim Gartenberg\\n                    \\n\\n Jan 22, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEntrepreneurs\\nA new accelerator for AI-first startups in North America\\n\\n\\n\\n                  By\\n                  \\n                    \\n                    Ryan Kiskis\\n                    \\n\\n                    Matt Ridenour\\n                    \\n\\n Jan 18, 2024\\n\\n\\n\\n\\n\\n\\n.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLet’s stay in touch. Get the latest news from Google in your inbox.\\n\\n\\nSubscribe\\nNo thanks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Follow Us\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPrivacy\\n            \\n\\n\\nTerms\\n            \\n\\n\\nAbout Google\\n            \\n\\n\\nGoogle Products\\n            \\n\\n\\nAbout the Keyword\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n              Help\\n            \\n\\n\\n\\n\\n\\n        Deutsch\\n      \\n\\n        English\\n      \\n\\n        English (Africa)\\n      \\n\\n        English (Australia)\\n      \\n\\n        English (Canada)\\n      \\n\\n        English (India)\\n      \\n\\n        English (MENA)\\n      \\n\\n        Español (España)\\n      \\n\\n        Español (Latinoamérica)\\n      \\n\\n        Français (Canada)\\n      \\n\\n        Français (France)\\n      \\n\\n        Italiano\\n      \\n\\n        Polski\\n      \\n\\n        Português (Brasil)\\n      \\n\\n        اللغة العربية (MENA)\\n      \\n\\n        한국어\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://blog.google/technology/ai/google-gemini-ai/#sundar-note', 'title': 'Introducing Gemini: Google’s most capable AI model yet', 'description': 'Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.', 'language': 'en-us'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature =0.7, top_p=0.85)"
      ],
      "metadata": {
        "id": "_7oxJhm83Rey"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
        "llm_prompt = PromptTemplate.from_template(\"Write a concise summary of the following : {text} \\n\\n Summary:\")\n",
        "\n",
        "print(doc_prompt)\n",
        "print(llm_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oezZTOTi5oe6",
        "outputId": "923239b7-2cb5-4f36-eaf6-b51aad215ac6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['page_content'] template='{page_content}'\n",
            "input_variables=['text'] template='Write a concise summary of the following : {text} \\n\\n Summary:'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.prompt_template import format_document\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "stuff_chain = (\n",
        "        {\"text\": lambda docs: \"\\n\\n\".join(\n",
        "    format_document(doc, doc_prompt) for doc in docs)}\n",
        "        | llm_prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "uKGvg70z-oop",
        "outputId": "a24d1607-ab0f-4ccd-a502-f1cf0bcf6ea2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'text' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dfe50723dab8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m stuff_chain = ( \n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mformat_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m|\u001b[0m \u001b[0mllm_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_chain.invoke(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "H9zPMEmyCjHA",
        "outputId": "8f2c5354-0db6-4091-cf54-4afa0fcba5b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google introduces Gemini, its most capable and general AI model yet. Gemini is multimodal, flexible, and efficient, with state-of-the-art performance across various benchmarks. It excels in sophisticated reasoning, understanding text, images, audio, and code, and generating high-quality code. Gemini is designed with responsibility and safety at its core, undergoing comprehensive safety evaluations and incorporating dedicated safety classifiers. It is being rolled out across Google products, including Bard, Pixel, Search, and Ads, and will be available to developers and enterprise customers via the Gemini API. Gemini Ultra, the most advanced version, will undergo further trust and safety checks before being made broadly available. Google aims to responsibly advance AI capabilities and transform the way people live and work worldwide.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model works, let me check what output it will give for my text in the example shared earlier.\n",
        "\n",
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "Gemini's Summary: ?"
      ],
      "metadata": {
        "id": "SOAsuWMxSUMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs=[Document(page_content=\"Psychologist Dr. Jessica Zucker, author of 'I Had a Miscarriage: \\\n",
        "A Memoir, A Movement,' tells TODAY.com that people generally refer to a baby born after a pregnancy loss,\\\n",
        " infant death, stillbirth or miscarriage as a rainbow baby.\")]\n",
        "\n",
        "stuff_chain = (\n",
        "        {\"text\": lambda docs: \"\\n\\n\".join(format_document(doc, doc_prompt) for doc in docs)}\n",
        "        | llm_prompt | llm | StrOutputParser()\n",
        "        )\n",
        "\n",
        "stuff_chain.invoke(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zesF2hABSdnV",
        "outputId": "12e362e4-9892-47a3-ac26-0d2aa1a4a63f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A rainbow baby is a term used to describe a baby born after a pregnancy loss, infant death, stillbirth, or miscarriage. The term is meant to symbolize hope and joy after a difficult experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text: Psychologist Dr. Jessica Zucker, author of \"I Had a Miscarriage: A Memoir, A Movement,\" tells TODAY.com that people generally refer to a baby born after a pregnancy loss, infant death, stillbirth or miscarriage as a rainbow baby.\n",
        "\n",
        "My Summary: A rainbow baby is a baby born after some kind of loss such as a miscarriage.\n",
        "\n",
        "Gemini's Summary: A rainbow baby is a term used to describe a baby born after a pregnancy loss, infant death, stillbirth, or miscarriage. The term is meant to symbolize hope and joy after a difficult experience."
      ],
      "metadata": {
        "id": "WLd8CIgkae7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "This is interesting, isn't it? has not only selected a key sentence from the given input but also managed to add an additional sentence from its general knowledge bringing out the broad meaning of the term 'rainbow baby'. Gemini also has nicely ignored the details of the psychologist just as I would do :)"
      ],
      "metadata": {
        "id": "PJYoJ1pmbFeb"
      }
    }
  ]
}